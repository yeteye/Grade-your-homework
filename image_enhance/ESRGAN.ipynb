{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义RRDB块\n",
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, num_filters=64, growth_channel=32):\n",
    "        super(ResidualDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_filters, growth_channel, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(num_filters + growth_channel, growth_channel, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(num_filters + 2 * growth_channel, growth_channel, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(num_filters + 3 * growth_channel, growth_channel, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(num_filters + 4 * growth_channel, num_filters, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        x1 = torch.relu(self.conv1(x))\n",
    "        x2 = torch.relu(self.conv2(torch.cat([x, x1], dim=1)))\n",
    "        x3 = torch.relu(self.conv3(torch.cat([x, x1, x2], dim=1)))\n",
    "        x4 = torch.relu(self.conv4(torch.cat([x, x1, x2, x3], dim=1)))\n",
    "        x5 = self.conv5(torch.cat([x, x1, x2, x3, x4], dim=1))\n",
    "        return x5 * 0.2 + inputs  # 使用缩放因子稳定训练\n",
    "\n",
    "# 定义生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_filters=64, num_blocks=23):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Conv2d(3, num_filters, kernel_size=3, padding=1)\n",
    "        self.rrdb_blocks = nn.Sequential(*[ResidualDenseBlock(num_filters) for _ in range(num_blocks)])\n",
    "        self.conv_hr = nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv_last = nn.Conv2d(num_filters, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.rrdb_blocks(initial)\n",
    "        x = self.conv_hr(x) + initial  # 残差连接\n",
    "        x = self.conv_last(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for i in range(4):\n",
    "            out_channels = 64 * (2 ** i)\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            in_channels = out_channels\n",
    "        layers.append(nn.Conv2d(out_channels, 1, 4, padding=0))  # 判别器输出一个值\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# 使用预训练的VGG模型计算感知损失\n",
    "class VGGFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGFeatureExtractor, self).__init__()\n",
    "        vgg19 = models.vgg19(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg19.features)[:18])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化生成器和判别器\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "feature_extractor = VGGFeatureExtractor().eval()  # VGG用于感知损失\n",
    "\n",
    "# 定义损失函数\n",
    "pixel_loss = nn.MSELoss()\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for lr_img, hr_img in dataloader:\n",
    "        # ---------------------\n",
    "        # 训练判别器\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        real_output = discriminator(hr_img)\n",
    "        fake_img = generator(lr_img)\n",
    "        fake_output = discriminator(fake_img.detach())\n",
    "        \n",
    "        d_loss_real = adversarial_loss(real_output, torch.ones_like(real_output))\n",
    "        d_loss_fake = adversarial_loss(fake_output, torch.zeros_like(fake_output))\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ---------------------\n",
    "        # 训练生成器\n",
    "        # ---------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_output = discriminator(fake_img)\n",
    "        \n",
    "        # 像素损失\n",
    "        pix_loss = pixel_loss(fake_img, hr_img)\n",
    "        \n",
    "        # 感知损失\n",
    "        real_features = feature_extractor(hr_img)\n",
    "        fake_features = feature_extractor(fake_img)\n",
    "        perceptual_loss = pixel_loss(fake_features, real_features)\n",
    "        \n",
    "        # 对抗损失\n",
    "        adv_loss = adversarial_loss(fake_output, torch.ones_like(fake_output))\n",
    "\n",
    "        # 综合损失\n",
    "        g_loss = pix_loss + 0.006 * perceptual_loss + 0.001 * adv_loss\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
